{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel, LdaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5960f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ignis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ignis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ignis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ignis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd002984-c0f3-45f8-9360-eca2f2ada2c8",
   "metadata": {},
   "source": [
    "### Pre-processing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45efb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['wheat', 'ndvi', 'yield', 'index', 'used', 'study', 'yields',\n",
    "           'figure', 'table', 'crop', 'grain', 'data', 'values', 'using', \n",
    "           'das', 'org', 'https', 'indices', 'cambridge', 'fig', 'based']\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [lemma.lemmatize(word) for word in tokens if (word not in stopwords.words('english')) & (word.isalpha()) & (len(word) > 2) & (word not in  exclude)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024361a3-66a4-4822-a9b9-a60d71cab702",
   "metadata": {},
   "source": [
    "### Loading abstracts saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859271ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abstract/abstracts.pkl', 'rb') as f:\n",
    "    mynewlist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de173a-1552-4785-a0d9-94bacc52c60c",
   "metadata": {},
   "source": [
    "### Cleaning abstracts and dictionary and corpus generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ab93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess documents\n",
    "cleaned_documents = [preprocess(doc) for doc in mynewlist]\n",
    "\n",
    "# Create a Gensim dictionary (maps words to unique IDs)\n",
    "dictionary = Dictionary(cleaned_documents)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "# Convert documents into Bag-of-Words (BoW) format\n",
    "corpus = [dictionary.doc2bow(doc) for doc in cleaned_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d6968-3852-407d-a73e-9e8af13d4a4a",
   "metadata": {},
   "source": [
    "### Setting number of topics based on coherence search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.3131632749269663\n",
      "2 0.3463469852561647\n",
      "3 0.430446746385031\n",
      "4 0.4488423965591819\n",
      "5 0.458004051671819\n",
      "6 0.4406702703881347\n",
      "7 0.4295771105599457\n",
      "8 0.4546196515122478\n",
      "9 0.4314436382168376\n",
      "10 0.40974343561597193\n",
      "11 0.41227611849411955\n",
      "12 0.4117090180226442\n",
      "13 0.40917163850628263\n",
      "14 0.3987671225270203\n",
      "15 0.4094540261218962\n",
      "16 0.3862611192137477\n",
      "17 0.38518539351763154\n",
      "18 0.40143966625216726\n",
      "19 0.3899832125825437\n"
     ]
    }
   ],
   "source": [
    "cohe = []\n",
    "for n in range(1, 30):\n",
    "    n_topics = n\n",
    "    \n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, random_state=42, passes=10, iterations=50)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=cleaned_documents, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(n, coherence_score)\n",
    "    cohe.append(coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac67b87-3a3d-4d93-ae09-0e1651a9691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,30), cohe)\n",
    "plt.xlabel(\"Number of Topics\", fontsize=12)\n",
    "plt.ylabel(\"Coherence Score\", fontsize=12)\n",
    "# plt.savefig('coherence.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00691e31-ebc9-4297-9da0-2d04ae70873a",
   "metadata": {},
   "source": [
    "### Training LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9a669-e4e8-4c0f-8404-52441d76602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "n_topics = 5\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, random_state=42, passes=10, iterations=50)\n",
    "\n",
    "# Print the topics and their top words\n",
    "for i, topic in lda_model.show_topics(num_topics=n_topics, num_words=6, formatted=False):\n",
    "    print(f\"Topic {i + 1}: {[word for word, prob in topic]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73992165-74d9-4ddc-b2a8-8c53dba6332e",
   "metadata": {},
   "source": [
    "### Topics and interclass distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdef03e-2d29-4b4e-b9dc-f292eb277b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1dab3-3dab-477f-8f58-19bb6a085050",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(6, 8))\n",
    "\n",
    "for i in range(1, 6):\n",
    "    df = panel.sorted_terms(i)\n",
    "    if i < 3:\n",
    "        j = i - 1\n",
    "        ax[0, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Total'][::-1], alpha=0.5)\n",
    "        ax[0, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Freq'][::-1], alpha=0.6)\n",
    "        ax[0, j].set_title(f\"Topic {i}\")\n",
    "        ax[0, j].set_xlim(0, 2100)\n",
    "        ax[0, j].grid(axis='x')\n",
    "        \n",
    "    elif (i >= 3) & (i < 5):\n",
    "        j = i - 3\n",
    "        ax[1, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Total'][::-1], alpha=0.5)\n",
    "        ax[1, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Freq'][::-1], alpha=0.6)\n",
    "        ax[1, j].set_title(f\"Topic {i}\")\n",
    "        ax[1, j].set_xlim(0, 2100)\n",
    "        ax[1, j].grid(axis='x')\n",
    "\n",
    "    else:\n",
    "        j = i - 5\n",
    "        ax[2, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Total'][::-1], alpha=0.5)\n",
    "        ax[2, j].barh(df.head(7)['Term'][::-1].str.capitalize(), \n",
    "                          df.head(7)['Freq'][::-1], alpha=0.6)\n",
    "        ax[2, j].set_title(f\"Topic {i}\")\n",
    "        ax[2, j].set_xlim(0, 2100)\n",
    "        ax[2, j].grid(axis='x')\n",
    "        \n",
    "\n",
    "    ax[2, 1].axis('off')\n",
    "            \n",
    "plt.tight_layout()\n",
    "# plt.savefig('LDA_freq.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565bcac-8016-4789-8dd5-be23315ee859",
   "metadata": {},
   "source": [
    "### Co-occurring topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85012f-deb7-458b-9407-8f20a3751d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(lda_model, topn=3):\n",
    "    topics = lda_model.show_topics(num_topics=-1, num_words=topn, formatted=False)\n",
    "    return {topic[0]: \" \".join([word for word, _ in topic[1]]) for topic in topics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98aee45-f882-4d27-8feb-c3fb790263b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Topic 4', 'Topic 5', 'Topic 1', 'Topic 3', 'Topic 2']\n",
    "topic_distributions = [lda_model.get_document_topics(bow) for bow in corpus]\n",
    "most_likely_topics = [max(topics, key=lambda x: x[1])[0] for topics in topic_distributions]\n",
    "all_probabilities = [prob for topics in topic_distributions for _, prob in topics]\n",
    "topic_titles = get_topic_titles(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48932d-8ac5-4fbb-9d0c-57368d27d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold as the 90th percentile of all topic probabilities\n",
    "threshold = np.percentile(all_probabilities, 50)\n",
    "\n",
    "# threshold = 0.02\n",
    "co_occurrence_matrix = Counter()\n",
    "for topics in topic_distributions:\n",
    "    top_topics = [topic[0] for topic in topics if topic[1] > threshold]  # Use a threshold for multiple topics\n",
    "    co_occurrence_matrix.update(combinations(top_topics, 2))\n",
    "\n",
    "# Example: Heatmap visualization\n",
    "topics = list(range(lda_model.num_topics))\n",
    "print(topics, topic_titles)\n",
    "matrix = np.zeros((len(topics), len(topics)))\n",
    "for (t1, t2), count in co_occurrence_matrix.items():\n",
    "    matrix[t1, t2] = count\n",
    "    matrix[t2, t1] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6a2a9-ce1c-4241-92d7-8b728f8c7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matrix, cmap=\"viridis\")#xticklabels=topics, yticklabels=topics, )\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Number of documents', fontsize=12)\n",
    "plt.xticks(range(5), labels)#['4', '5', '1', '3', '2'])\n",
    "plt.yticks(range(5), labels)\n",
    "plt.tick_params(axis='x', rotation=90)\n",
    "# plt.savefig('co-occurrence.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
